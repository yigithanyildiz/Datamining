import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
from torch_geometric.explain import Explainer, GNNExplainer
import matplotlib.pyplot as plt
import networkx as nx
from torch_geometric.utils import to_networkx, k_hop_subgraph

# =====================
# 1. AYARLAR & YÃœKLEME
# =====================
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

try:
    data = torch.load("amazon_office_graph.pt", weights_only=False)
    data = data.to(device)
except FileNotFoundError:
    print("HATA: 'amazon_office_graph.pt' bulunamadÄ±.")
    exit()

# --- BÄ°LÄ°MSEL KONTROL: Feature Leakage Ã–nlemi ---
# (Step 1'deki gibi puanÄ± siliyoruz ki model yapÄ±ya baksÄ±n)
if data.x.shape[1] > 0:
    data.x[:, 0] = 0.0 

num_features = data.x.shape[1]
num_classes = 2

# =====================
# 2. MODELÄ° HAZIRLA (Step 1'deki Modelin AynÄ±sÄ±)
# =====================
class GCN(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = GCNConv(num_features, 64)
        self.conv2 = GCNConv(64, 32)
        self.conv3 = GCNConv(32, num_classes)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.conv2(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.conv3(x, edge_index)
        return x

print("Model hazÄ±rlanÄ±yor ve hÄ±zlÄ±ca eÄŸitiliyor...")
model = GCN().to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
criterion = torch.nn.CrossEntropyLoss()

# Explanation iÃ§in modelin biraz eÄŸitilmiÅŸ olmasÄ± lazÄ±m
# (Step 1'de kanÄ±tladÄ±ÄŸÄ±mÄ±z yapÄ±yÄ± Ã¶ÄŸrensin)
model.train()
# Sadece valid user'larÄ± al
valid_mask = data.y != -1
train_idx = torch.where(valid_mask)[0]

# HÄ±zlÄ± eÄŸitim (Explanation testi iÃ§in)
for epoch in range(100):
    optimizer.zero_grad()
    out = model(data.x, data.edge_index)
    loss = criterion(out[train_idx], data.y[train_idx])
    loss.backward()
    optimizer.step()

# =====================
# 3. HEDEF KULLANICI SEÃ‡Ä°MÄ°
# =====================
model.eval()
out = model(data.x, data.edge_index)
pred = out.argmax(dim=1)

# Modelin "Memnun (1)" dediÄŸi ve GerÃ§ekte de "Memnun (1)" olan birini bul
target_node = -1
for i in train_idx:
    if data.y[i] == 1 and pred[i] == 1:
        # Biraz baÄŸlantÄ±sÄ± olan birini seÃ§elim ki gÃ¶rsel gÃ¼zel olsun (degree > 2)
        degree = (data.edge_index[0] == i).sum().item()
        if degree > 2 and degree < 20: # Ã‡ok kalabalÄ±k da olmasÄ±n
            target_node = i.item()
            break

if target_node == -1:
    print("Uygun hedef kullanÄ±cÄ± bulunamadÄ±, rastgele biri seÃ§iliyor.")
    target_node = train_idx[0].item()

print(f"\nğŸ¯ Hedef KullanÄ±cÄ± Node ID: {target_node}")
print(f"GerÃ§ek Etiket: {data.y[target_node].item()} | Tahmin: {pred[target_node].item()}")

# =====================
# 4. GNNEXPLAINER (Single-Objective)
# =====================
print("\nğŸ” GNNExplainer Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±yor (Single-Objective: Fidelity)...")

explainer = Explainer(
    model=model,
    algorithm=GNNExplainer(epochs=200),
    explanation_type='model',
    node_mask_type='attributes',
    edge_mask_type='object',
    model_config=dict(
        mode='multiclass_classification',
        task_level='node',
        return_type='raw',
    ),
)

# AÃ§Ä±klamayÄ± Ã¼ret
explanation = explainer(
    x=data.x,
    edge_index=data.edge_index,
    index=target_node
)

# =====================
# 5. GÃ–RSELLEÅTÄ°RME VE ANALÄ°Z
# =====================
# Ã–nemli kenarlarÄ± seÃ§ (Threshold: 0.5 Ã¼stÃ¼)
edge_mask = explanation.edge_mask
important_edges_mask = edge_mask > 0.5
num_important = important_edges_mask.sum().item()

print(f"\nğŸ“Š Analiz SonuÃ§larÄ±:")
print(f"Toplam KomÅŸuluk (Edge): {edge_mask.shape[0]}")
print(f"Explanation Ä°Ã§in SeÃ§ilen Edge SayÄ±sÄ±: {num_important}")

# GÃ¶rselleÅŸtirme (Subgraph)
# Sadece hedef node ve onun 2-hop komÅŸularÄ±nÄ± al
subset, sub_edge_index, mapping, _ = k_hop_subgraph(
    target_node, 2, data.edge_index, relabel_nodes=True
)

# NetworkX'e Ã§evir
data_sub = torch.load("amazon_office_graph.pt", weights_only=False) # Featurelar iÃ§in tekrar yÃ¼kle
g = to_networkx(data, to_undirected=True)
sub_g = g.subgraph(subset.tolist())

plt.figure(figsize=(10, 8))
pos = nx.spring_layout(sub_g, seed=42)

# TÃ¼m dÃ¼ÄŸÃ¼mleri gri Ã§iz
nx.draw_networkx_nodes(sub_g, pos, node_size=100, node_color='#bdc3c7', alpha=0.5)
# Hedef dÃ¼ÄŸÃ¼mÃ¼ KÄ±rmÄ±zÄ± Ã§iz
nx.draw_networkx_nodes(sub_g, pos, nodelist=[target_node], node_size=300, node_color='#e74c3c')
# TÃ¼m kenarlarÄ± silik Ã§iz
nx.draw_networkx_edges(sub_g, pos, alpha=0.1)

# --- Explanation Edges ---
# GNNExplainer'Ä±n "Ã¶nemli" dediÄŸi kenarlarÄ± bulup Ã¼stÃ¼ne Ã§izelim
# (Mapping iÅŸlemi karmaÅŸÄ±k olduÄŸu iÃ§in burada basitleÅŸtirilmiÅŸ gÃ¶rselleÅŸtirme yapÄ±yoruz)
# Bu demo gÃ¶rselidir, raporda "Ã¶nemli kenar sayÄ±sÄ±" verisini kullanacaÄŸÄ±z.

plt.title(f"GNNExplainer Result for User {target_node}\nSelected Edges: {num_important}", fontsize=14)
plt.axis('off')
plt.savefig("gnn_explainer_result.png")
print("âœ… GÃ¶rsel kaydedildi: gnn_explainer_result.png")

print("\n--- YORUM ---")
if num_important < 2:
    print("ğŸ‘‰ SONUÃ‡: Explanation Ã§ok 'Sparse' (Seyrek). Belki yetersiz bilgi veriyor.")
    print("FarklÄ± bir run yaparsak sonuÃ§ deÄŸiÅŸebilir (Instability).")
elif num_important > 10:
    print("ğŸ‘‰ SONUÃ‡: Explanation Ã§ok 'Dense' (YoÄŸun). OkunabilirliÄŸi dÃ¼ÅŸÃ¼k.")
    print("YÃ¶netici (Manager) bu aÃ§Ä±klamayÄ± anlamaz (User Requirement Conflict).")
else:
    print("ğŸ‘‰ SONUÃ‡: Makul bir aÃ§Ä±klama. Ancak sadece 'Fidelity' odaklÄ±.")